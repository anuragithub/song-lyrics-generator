{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "ps = nltk.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_data(len):\n",
    "    lyrics_data = pd.read_csv(\"../data/380000-lyrics-from-metrolyrics/lyrics.csv\")\n",
    "\n",
    "    lyrics_data.head(4)\n",
    "\n",
    "    lyrics_data = lyrics_data[pd.notnull(lyrics_data['lyrics'])]\n",
    "\n",
    "    lyrics_data_sample = lyrics_data[0:len]\n",
    "\n",
    "    lyrics_data_sample.head(4)\n",
    "\n",
    "    def clean_text(text):\n",
    "        text = text.replace('--', ' ')\n",
    "        tokens = text.split()\n",
    "        table = str.maketrans('', '', string.punctuation)\n",
    "        tokens = [w.translate(table) for w in tokens]\n",
    "        tokens = [word for word in tokens if word.isalpha()]\n",
    "        tokens = [word.lower() for word in tokens]\n",
    "        return tokens\n",
    "\n",
    "    lyrics_data_sample['lyrics'] = lyrics_data_sample['lyrics'].apply(lambda x: clean_text(x))\n",
    "    return lyrics_data_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\projects\\env\\lib\\site-packages\\ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "data = gen_data(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>song</th>\n",
       "      <th>year</th>\n",
       "      <th>artist</th>\n",
       "      <th>genre</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ego-remix</td>\n",
       "      <td>2009</td>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>[oh, baby, how, you, doing, you, know, im, gon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>then-tell-me</td>\n",
       "      <td>2009</td>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>[playin, everything, so, easy, its, like, you,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>honesty</td>\n",
       "      <td>2009</td>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>[if, you, search, for, tenderness, it, isnt, h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>you-are-my-rock</td>\n",
       "      <td>2009</td>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>[oh, oh, oh, i, oh, oh, oh, i, verse, if, i, w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index             song  year           artist genre  \\\n",
       "0      0        ego-remix  2009  beyonce-knowles   Pop   \n",
       "1      1     then-tell-me  2009  beyonce-knowles   Pop   \n",
       "2      2          honesty  2009  beyonce-knowles   Pop   \n",
       "3      3  you-are-my-rock  2009  beyonce-knowles   Pop   \n",
       "\n",
       "                                              lyrics  \n",
       "0  [oh, baby, how, you, doing, you, know, im, gon...  \n",
       "1  [playin, everything, so, easy, its, like, you,...  \n",
       "2  [if, you, search, for, tenderness, it, isnt, h...  \n",
       "3  [oh, oh, oh, i, oh, oh, oh, i, verse, if, i, w...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = list()\n",
    "for row in data['lyrics']:\n",
    "    tokens += row\n",
    "\n",
    "length = 51\n",
    "lines = list()\n",
    "for i in range(0,len(tokens)-len(tokens)%length,length):\n",
    "    seq = tokens[i:i+length]\n",
    "    line = ' '.join(seq)\n",
    "    lines.append(line)\n",
    "print('Total Sequences: %d' % len(lines))\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(lines)\n",
    "sequences = tokenizer.texts_to_sequences(lines)\n",
    "\n",
    "sequences = np.array(sequences)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "X, y = sequences[:,:-1], sequences[:,-1]\n",
    "seq_length = X.shape[1]\n",
    "\n",
    "X.shape\n",
    "\n",
    "y = to_categorical(y, num_classes=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From f:\\projects\\env\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 50, 50)            149950    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 50, 100)           60400     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2999)              302899    \n",
      "=================================================================\n",
      "Total params: 603,749\n",
      "Trainable params: 603,749\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 50, input_length=seq_length))\n",
    "model.add(LSTM(100, return_sequences=True))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"410pt\" viewBox=\"0.00 0.00 171.00 410.00\" width=\"171pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 406)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-406 167,-406 167,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 1559141753464 -->\n",
       "<g class=\"node\" id=\"node1\"><title>1559141753464</title>\n",
       "<polygon fill=\"none\" points=\"0,-292.5 0,-328.5 163,-328.5 163,-292.5 0,-292.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"81.5\" y=\"-306.8\">embedding_1: Embedding</text>\n",
       "</g>\n",
       "<!-- 1559141753968 -->\n",
       "<g class=\"node\" id=\"node2\"><title>1559141753968</title>\n",
       "<polygon fill=\"none\" points=\"32.5,-219.5 32.5,-255.5 130.5,-255.5 130.5,-219.5 32.5,-219.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"81.5\" y=\"-233.8\">lstm_1: LSTM</text>\n",
       "</g>\n",
       "<!-- 1559141753464&#45;&gt;1559141753968 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>1559141753464-&gt;1559141753968</title>\n",
       "<path d=\"M81.5,-292.313C81.5,-284.289 81.5,-274.547 81.5,-265.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"85.0001,-265.529 81.5,-255.529 78.0001,-265.529 85.0001,-265.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1559141756040 -->\n",
       "<g class=\"node\" id=\"node3\"><title>1559141756040</title>\n",
       "<polygon fill=\"none\" points=\"32.5,-146.5 32.5,-182.5 130.5,-182.5 130.5,-146.5 32.5,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"81.5\" y=\"-160.8\">lstm_2: LSTM</text>\n",
       "</g>\n",
       "<!-- 1559141753968&#45;&gt;1559141756040 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>1559141753968-&gt;1559141756040</title>\n",
       "<path d=\"M81.5,-219.313C81.5,-211.289 81.5,-201.547 81.5,-192.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"85.0001,-192.529 81.5,-182.529 78.0001,-192.529 85.0001,-192.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1559141937840 -->\n",
       "<g class=\"node\" id=\"node4\"><title>1559141937840</title>\n",
       "<polygon fill=\"none\" points=\"29.5,-73.5 29.5,-109.5 133.5,-109.5 133.5,-73.5 29.5,-73.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"81.5\" y=\"-87.8\">dense_1: Dense</text>\n",
       "</g>\n",
       "<!-- 1559141756040&#45;&gt;1559141937840 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>1559141756040-&gt;1559141937840</title>\n",
       "<path d=\"M81.5,-146.313C81.5,-138.289 81.5,-128.547 81.5,-119.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"85.0001,-119.529 81.5,-109.529 78.0001,-119.529 85.0001,-119.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1559143161928 -->\n",
       "<g class=\"node\" id=\"node5\"><title>1559143161928</title>\n",
       "<polygon fill=\"none\" points=\"29.5,-0.5 29.5,-36.5 133.5,-36.5 133.5,-0.5 29.5,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"81.5\" y=\"-14.8\">dense_2: Dense</text>\n",
       "</g>\n",
       "<!-- 1559141937840&#45;&gt;1559143161928 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>1559141937840-&gt;1559143161928</title>\n",
       "<path d=\"M81.5,-73.3129C81.5,-65.2895 81.5,-55.5475 81.5,-46.5691\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"85.0001,-46.5288 81.5,-36.5288 78.0001,-46.5289 85.0001,-46.5288\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1559141755648 -->\n",
       "<g class=\"node\" id=\"node6\"><title>1559141755648</title>\n",
       "<polygon fill=\"none\" points=\"29.5,-365.5 29.5,-401.5 133.5,-401.5 133.5,-365.5 29.5,-365.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"81.5\" y=\"-379.8\">1559141755648</text>\n",
       "</g>\n",
       "<!-- 1559141755648&#45;&gt;1559141753464 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>1559141755648-&gt;1559141753464</title>\n",
       "<path d=\"M81.5,-365.313C81.5,-357.289 81.5,-347.547 81.5,-338.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"85.0001,-338.529 81.5,-328.529 78.0001,-338.529 85.0001,-338.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From f:\\projects\\env\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/50\n",
      "718/718 [==============================] - 10s 14ms/step - loss: 8.0030 - acc: 0.0279\n",
      "Epoch 2/50\n",
      "718/718 [==============================] - 2s 3ms/step - loss: 7.9688 - acc: 0.0501\n",
      "Epoch 3/50\n",
      "718/718 [==============================] - 2s 3ms/step - loss: 7.5106 - acc: 0.0501\n",
      "Epoch 4/50\n",
      "718/718 [==============================] - 2s 3ms/step - loss: 6.4214 - acc: 0.0501\n",
      "Epoch 5/50\n",
      "718/718 [==============================] - 2s 3ms/step - loss: 5.5810 - acc: 0.0501\n",
      "Epoch 6/50\n",
      "718/718 [==============================] - 2s 3ms/step - loss: 5.4810 - acc: 0.0460\n",
      "Epoch 7/50\n",
      "718/718 [==============================] - 2s 3ms/step - loss: 5.3935 - acc: 0.0376\n",
      "Epoch 8/50\n",
      "718/718 [==============================] - 2s 3ms/step - loss: 5.3603 - acc: 0.0362\n",
      "Epoch 9/50\n",
      "718/718 [==============================] - 2s 3ms/step - loss: 5.3541 - acc: 0.0501\n",
      "Epoch 10/50\n",
      "718/718 [==============================] - 2s 3ms/step - loss: 5.3466 - acc: 0.0501\n",
      "Epoch 11/50\n",
      "718/718 [==============================] - 2s 3ms/step - loss: 5.3393 - acc: 0.0501\n",
      "Epoch 12/50\n",
      "718/718 [==============================] - 2s 3ms/step - loss: 5.3361 - acc: 0.0348\n",
      "Epoch 13/50\n",
      "718/718 [==============================] - 2s 3ms/step - loss: 5.3339 - acc: 0.0501\n",
      "Epoch 14/50\n",
      "718/718 [==============================] - 2s 3ms/step - loss: 5.3345 - acc: 0.0501\n",
      "Epoch 15/50\n",
      "718/718 [==============================] - 2s 3ms/step - loss: 5.3320 - acc: 0.0501\n",
      "Epoch 16/50\n",
      "718/718 [==============================] - 2s 3ms/step - loss: 5.3323 - acc: 0.0501\n",
      "Epoch 17/50\n",
      "718/718 [==============================] - 2s 3ms/step - loss: 5.3328 - acc: 0.0501\n",
      "Epoch 18/50\n",
      "718/718 [==============================] - 2s 3ms/step - loss: 5.3327 - acc: 0.0501\n",
      "Epoch 19/50\n",
      "718/718 [==============================] - 2s 3ms/step - loss: 5.3288 - acc: 0.0501\n",
      "Epoch 20/50\n",
      "718/718 [==============================] - 2s 3ms/step - loss: 5.3297 - acc: 0.0501\n",
      "Epoch 21/50\n",
      "718/718 [==============================] - 2s 3ms/step - loss: 5.3306 - acc: 0.0501\n",
      "Epoch 22/50\n",
      "718/718 [==============================] - 2s 3ms/step - loss: 5.3316 - acc: 0.0501\n",
      "Epoch 23/50\n",
      "718/718 [==============================] - 2s 3ms/step - loss: 5.3284 - acc: 0.0501\n",
      "Epoch 24/50\n",
      "718/718 [==============================] - 2s 3ms/step - loss: 5.3289 - acc: 0.0501\n",
      "Epoch 25/50\n",
      "718/718 [==============================] - 2s 3ms/step - loss: 5.3327 - acc: 0.0501\n",
      "Epoch 26/50\n",
      "718/718 [==============================] - 2s 3ms/step - loss: 5.3294 - acc: 0.0501\n",
      "Epoch 27/50\n",
      "718/718 [==============================] - 2s 3ms/step - loss: 5.3298 - acc: 0.0501\n",
      "Epoch 28/50\n",
      "718/718 [==============================] - 2s 3ms/step - loss: 5.3318 - acc: 0.0501\n",
      "Epoch 29/50\n",
      "718/718 [==============================] - 2s 3ms/step - loss: 5.3300 - acc: 0.0501\n",
      "Epoch 30/50\n",
      "718/718 [==============================] - 2s 3ms/step - loss: 5.3265 - acc: 0.0501\n",
      "Epoch 31/50\n",
      "718/718 [==============================] - 2s 3ms/step - loss: 5.3261 - acc: 0.0501\n",
      "Epoch 32/50\n",
      "718/718 [==============================] - 2s 3ms/step - loss: 5.3262 - acc: 0.0501\n",
      "Epoch 33/50\n",
      "718/718 [==============================] - 2s 3ms/step - loss: 5.3291 - acc: 0.0501\n",
      "Epoch 34/50\n",
      "718/718 [==============================] - 3s 4ms/step - loss: 5.3279 - acc: 0.0501\n",
      "Epoch 35/50\n",
      "718/718 [==============================] - 2s 3ms/step - loss: 5.3265 - acc: 0.0501\n",
      "Epoch 36/50\n",
      "718/718 [==============================] - 2s 3ms/step - loss: 5.3264 - acc: 0.0501\n",
      "Epoch 37/50\n",
      "718/718 [==============================] - 2s 3ms/step - loss: 5.3246 - acc: 0.0501\n",
      "Epoch 38/50\n",
      "718/718 [==============================] - 3s 4ms/step - loss: 5.3284 - acc: 0.0501\n",
      "Epoch 39/50\n",
      "718/718 [==============================] - 2s 3ms/step - loss: 5.3258 - acc: 0.0501\n",
      "Epoch 40/50\n",
      "718/718 [==============================] - 2s 3ms/step - loss: 5.3279 - acc: 0.0501\n",
      "Epoch 41/50\n",
      "718/718 [==============================] - 2s 3ms/step - loss: 5.3269 - acc: 0.0501\n",
      "Epoch 42/50\n",
      "718/718 [==============================] - 2s 3ms/step - loss: 5.3259 - acc: 0.0501\n",
      "Epoch 43/50\n",
      "718/718 [==============================] - 2s 3ms/step - loss: 5.3245 - acc: 0.0501\n",
      "Epoch 44/50\n",
      "718/718 [==============================] - 2s 3ms/step - loss: 5.3255 - acc: 0.0501\n",
      "Epoch 45/50\n",
      "718/718 [==============================] - 2s 3ms/step - loss: 5.3244 - acc: 0.0501\n",
      "Epoch 46/50\n",
      "718/718 [==============================] - 2s 3ms/step - loss: 5.3253 - acc: 0.0501\n",
      "Epoch 47/50\n",
      "718/718 [==============================] - 2s 3ms/step - loss: 5.3241 - acc: 0.0501\n",
      "Epoch 48/50\n",
      "718/718 [==============================] - 2s 3ms/step - loss: 5.3249 - acc: 0.0501\n",
      "Epoch 49/50\n",
      "718/718 [==============================] - 2s 3ms/step - loss: 5.3244 - acc: 0.0501\n",
      "Epoch 50/50\n",
      "718/718 [==============================] - 2s 3ms/step - loss: 5.3250 - acc: 0.0501\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16b644ce5c0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit model\n",
    "model.fit(X, y, batch_size=128, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_seq(model, tokenizer, seq_length, seed_text, n_words):\n",
    "\tresult = list()\n",
    "\tin_text = seed_text\n",
    "\t# generate a fixed number of words\n",
    "\tfor _ in range(n_words):\n",
    "\t\t# encode the text as integer\n",
    "\t\tencoded = tokenizer.texts_to_sequences([in_text])[0]\n",
    "\t\t# truncate sequences to a fixed length\n",
    "\t\tencoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n",
    "\t\t# predict probabilities for each word\n",
    "\t\tyhat = model.predict_classes(encoded, verbose=0)\n",
    "\t\t# map predicted word index to word\n",
    "\t\tout_word = ''\n",
    "\t\tfor word, index in tokenizer.word_index.items():\n",
    "\t\t\tif index == yhat:\n",
    "\t\t\t\tout_word = word\n",
    "\t\t\t\tbreak\n",
    "\t\t# append to input\n",
    "\t\tin_text += ' ' + out_word\n",
    "\t\tresult.append(out_word)\n",
    "\treturn ' '.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "generated = generate_seq(model, tokenizer, 50, lines[randint(0,len(lines))], 50)\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acssc %s sas\n"
     ]
    }
   ],
   "source": [
    "a='sas'\n",
    "print('acssc %s',a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
